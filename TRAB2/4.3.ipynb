{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a03e7ac-634c-4163-a16d-65f12d9440c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b63145-71f5-4585-8b43-6670800ddf5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de linhas duplicadas encontradas: 3600\n",
      "Linhas duplicadas removidas.\n"
     ]
    }
   ],
   "source": [
    "# 1. Carregar o dataset com separador e decimal corretos\n",
    "df = pd.read_csv(\"../AIRPOL_data.csv\", sep=\";\", decimal=\",\")\n",
    "\n",
    "# 2. Remover colunas que foram criadas automaticamente e estão vazias (ex: \"Unnamed\")\n",
    "df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "# 3. Contar e remover linhas duplicadas para evitar análises repetidas ou enviesadas\n",
    "duplicados = df.duplicated().sum()\n",
    "print(f\"\\nNúmero de linhas duplicadas encontradas: {duplicados}\")\n",
    "if duplicados > 0:\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"Linhas duplicadas removidas.\")\n",
    "\n",
    "    # Renomear coluna 'Value' para 'Premature_Deaths'\n",
    "    df.rename(columns={'Value': 'Premature_Deaths'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9ea61fa-c41a-4f3c-b591-61525f348fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas do dataset:\n",
      "['Country', 'NUTS_Code', 'Air_Pollutant', 'Outcome', 'Affected_Population', 'Populated_Area[km2]', 'Air_Pollution_Average[ug/m3]', 'Premature_Deaths']\n",
      "\n",
      "Primeiras linhas do dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>NUTS_Code</th>\n",
       "      <th>Air_Pollutant</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Affected_Population</th>\n",
       "      <th>Populated_Area[km2]</th>\n",
       "      <th>Air_Pollution_Average[ug/m3]</th>\n",
       "      <th>Premature_Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>NO2</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>2337443.0</td>\n",
       "      <td>11299.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>456076.0</td>\n",
       "      <td>11299.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL0</td>\n",
       "      <td>NO2</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>2337443.0</td>\n",
       "      <td>11299.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL0</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>456076.0</td>\n",
       "      <td>11299.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albania</td>\n",
       "      <td>AL03</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>Asthma</td>\n",
       "      <td>149508.0</td>\n",
       "      <td>4041.5</td>\n",
       "      <td>11.3</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country NUTS_Code Air_Pollutant Outcome  Affected_Population  \\\n",
       "0  Albania        AL           NO2  Asthma            2337443.0   \n",
       "1  Albania        AL         PM2.5  Asthma             456076.0   \n",
       "2  Albania       AL0           NO2  Asthma            2337443.0   \n",
       "3  Albania       AL0         PM2.5  Asthma             456076.0   \n",
       "4  Albania      AL03         PM2.5  Asthma             149508.0   \n",
       "\n",
       "   Populated_Area[km2]  Air_Pollution_Average[ug/m3]  Premature_Deaths  \n",
       "0              11299.0                           5.5             103.0  \n",
       "1              11299.0                          11.3             231.0  \n",
       "2              11299.0                           5.5             103.0  \n",
       "3              11299.0                          11.3             231.0  \n",
       "4               4041.5                          11.3              69.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Colunas do dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\nPrimeiras linhas do dataset:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4782a885-adb0-482e-99ca-00d75e4b5195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contagem por categoria:\n",
      "RespDisease\n",
      "Non-Respiratory    29317\n",
      "Respiratory        16223\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Proporção por categoria:\n",
      "RespDisease\n",
      "Non-Respiratory    0.643764\n",
      "Respiratory        0.356236\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4.3\n",
    "# ALÍNEA 1 — Derive um novo atributo RespDisease que separa as doenças em respiratórias\n",
    "# ('Asthma' 'Chronic obstructive pulmonary disease') e não respiratórias.\n",
    "# ============================================================\n",
    "\n",
    "# Lista de doenças respiratórias\n",
    "respiratory_diseases = ['Asthma', 'Chronic obstructive pulmonary disease']\n",
    "\n",
    "# Criar a coluna RespDisease\n",
    "df['RespDisease'] = np.where(df['Outcome'].isin(respiratory_diseases), 'Respiratory', 'Non-Respiratory')\n",
    "\n",
    "# Mostrar quantidade de cada categoria\n",
    "print(\"Contagem por categoria:\")\n",
    "print(df['RespDisease'].value_counts())\n",
    "\n",
    "print(\"\\nProporção por categoria:\")\n",
    "print(df['RespDisease'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "616fcfd3-6fc3-46ac-8711-92d3e1eaa444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparar X e y... feito.\n",
      "Treinar modelo: Árvore de Decisão... feito.\n",
      "Treinar modelo: Rede Neuronal... feito.\n",
      "Treinar modelo: SVM... feito.\n",
      "Treinar modelo: K-vizinhos... feito.\n",
      "\n",
      "Resumo dos resultados (média ± desvio padrão):\n",
      "\n",
      "                  Accuracy (mean±std) Sensitivity (mean±std)  \\\n",
      "Árvore de Decisão     0.7562 ± 0.0026        0.3301 ± 0.0120   \n",
      "Rede Neuronal         0.5321 ± 0.1609        0.6279 ± 0.3478   \n",
      "SVM                   0.6440 ± 0.0000        0.0006 ± 0.0001   \n",
      "K-vizinhos            0.7091 ± 0.0022        0.4436 ± 0.0075   \n",
      "\n",
      "                  Specificity (mean±std)    F1 (mean±std)  \n",
      "Árvore de Decisão        0.9920 ± 0.0037  0.4909 ± 0.0114  \n",
      "Rede Neuronal            0.4791 ± 0.4419  0.4549 ± 0.0819  \n",
      "SVM                      1.0000 ± 0.0000  0.0011 ± 0.0002  \n",
      "K-vizinhos               0.8560 ± 0.0030  0.5206 ± 0.0057  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4.3\n",
    "# ALÍNEA 2 — Usando o método k-fold cross validation desenvolva modelos de previsão de\n",
    "# RespDisease usando os seguintes métodos:\n",
    "# a) Árvore de decisão. Otimize os parâmetros do modelo.\n",
    "# b) Rede neuronal. Otimize a configuração da rede.\n",
    "# c) SVM. Otimize o kernel.\n",
    "# d) K-vizinhos-mais-próximos. Otimize o parâmetro K.\n",
    "# ============================================================\n",
    "\n",
    "# Seleção de variáveis preditoras e variável alvo\n",
    "features = ['Air_Pollution_Average[ug/m3]', 'Affected_Population', 'Populated_Area[km2]']\n",
    "X = df[features].copy()\n",
    "y = df['RespDisease']\n",
    "print(\"Preparar X e y... \", end=\"\")\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(\"feito.\")\n",
    "\n",
    "# Função para avaliar os modelos com k-fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    acc, sens, spec, f1 = [], [], [], []\n",
    "    for train_idx, test_idx in kfold.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc.append(accuracy_score(y_test, y_pred))\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        sens.append(tp / (tp + fn))\n",
    "        spec.append(tn / (tn + fp))\n",
    "    return {\n",
    "        \"Accuracy\": (np.mean(acc), np.std(acc)),\n",
    "        \"Sensitivity\": (np.mean(sens), np.std(sens)),\n",
    "        \"Specificity\": (np.mean(spec), np.std(spec)),\n",
    "        \"F1\": (np.mean(f1), np.std(f1))\n",
    "    }\n",
    "\n",
    "# Avaliação dos modelos\n",
    "results = {}\n",
    "\n",
    "modelos = {\n",
    "    'Árvore de Decisão': DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    'Rede Neuronal': MLPClassifier(hidden_layer_sizes=(10,), max_iter=1000, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42),\n",
    "    'K-vizinhos': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "for nome, modelo in modelos.items():\n",
    "    # Como alguns modelos podem demorar algum tempo faz-se este print para perceber qual está a ser processado\n",
    "    print(f\"Treinar modelo: {nome}... \", end=\"\")\n",
    "    results[nome] = evaluate_model(modelo, X, y_encoded)\n",
    "    print(\"feito.\")\n",
    "\n",
    "# Construir DataFrame com os resultados\n",
    "df_results = pd.DataFrame.from_dict(results, orient='index')\n",
    "df_results.columns = ['Accuracy (mean±std)', 'Sensitivity (mean±std)', 'Specificity (mean±std)', 'F1 (mean±std)']\n",
    "\n",
    "# Formatar as métricas para apresentação (média ± desvio padrão)\n",
    "def format_metric(mean_std):\n",
    "    mean, std = mean_std\n",
    "    return f\"{mean:.4f} ± {std:.4f}\"\n",
    "\n",
    "df_formatado = df_results.map(format_metric)\n",
    "\n",
    "# Mostrar resultados formatados\n",
    "print(\"\\nResumo dos resultados (média ± desvio padrão):\\n\")\n",
    "print(df_formatado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43a13da-c27b-4d21-a1ba-b509b31252f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4.3\n",
    "# ALÍNEA 3 — Obtenha a média e o desvio padrão da Accuracy;\n",
    "# Sensitivity; Specificity e F1 do atributo RespDisease com\n",
    "# os modelos obtidos na alínea anterior.\n",
    "# ============================================================\n",
    "\n",
    "def format_metric(mean_std):\n",
    "    mean, std = mean_std\n",
    "    return f\"{mean:.4f} ± {std:.4f}\"\n",
    "\n",
    "df_alinea3 = df_results.map(format_metric)\n",
    "\n",
    "print(\"Média e desvio padrão por modelo (alvo: RespDisease):\\n\")\n",
    "print(df_alinea3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46e21ab4-f1d1-4181-8e4c-ee591b3fcf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliar F1-score médio dos modelos... feito.\n",
      "Ordenar modelos pelo F1-score médio... feito.\n",
      "Modelos selecionados para comparação: K-vizinhos vs Árvore de Decisão\n",
      "Calcular F1-score por fold para K-vizinhos... feito.\n",
      "Calcular F1-score por fold para Árvore de Decisão... feito.\n",
      "Executar teste t pareado... feito.\n",
      "p-value = 0.0030\n",
      "Conclusão: diferença estatisticamente significativa.\n",
      "Modelo com melhor desempenho: K-vizinhos\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4.3\n",
    "# ALÍNEA 4 — Verifique se existe diferença significativa no desempenho\n",
    "# dos dois melhores modelos (nível de significância de 5%).\n",
    "# ============================================================\n",
    "\n",
    "# Hipóteses do teste estatístico:\n",
    "# H0 (hipótese nula): Não existe diferença significativa entre os modelos.\n",
    "# H1 (hipótese alternativa): Existe diferença significativa entre os modelos.\n",
    "# Nível de significância: α = 0.05\n",
    "\n",
    "# Utilizar os F1-scores médios previamente calculados na alínea 2 (results)\n",
    "print(\"Avaliar F1-score médio dos modelos... \", end=\"\")\n",
    "f1_scores = {nome: resultado['F1'] for nome, resultado in results.items()}\n",
    "print(\"feito.\")\n",
    "\n",
    "# Ordenar modelos pelo F1-score médio (posição 0 do tuplo: média)\n",
    "print(\"Ordenar modelos pelo F1-score médio... \", end=\"\")\n",
    "sorted_f1 = sorted(f1_scores.items(), key=lambda x: x[1][0], reverse=True)\n",
    "modelo_1, modelo_2 = sorted_f1[0][0], sorted_f1[1][0]\n",
    "print(\"feito.\")\n",
    "\n",
    "print(f\"Modelos selecionados para comparação: {modelo_1} vs {modelo_2}\")\n",
    "\n",
    "# Função para obter a lista de F1-scores (um por fold) — necessário para o teste estatístico\n",
    "def get_f1_list(model):\n",
    "    f1 = []\n",
    "    for train_idx, test_idx in kfold.split(X, y_encoded):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "    return f1\n",
    "\n",
    "# Recalcular listas de F1 por fold apenas para os dois modelos a comparar\n",
    "print(f\"Calcular F1-score por fold para {modelo_1}... \", end=\"\")\n",
    "f1_1 = get_f1_list(modelos[modelo_1])\n",
    "print(\"feito.\")\n",
    "\n",
    "print(f\"Calcular F1-score por fold para {modelo_2}... \", end=\"\")\n",
    "f1_2 = get_f1_list(modelos[modelo_2])\n",
    "print(\"feito.\")\n",
    "\n",
    "# Aplicar o teste t pareado (comparação estatística entre os dois modelos)\n",
    "print(\"Executar teste t pareado... \", end=\"\")\n",
    "stat, p_value = ttest_rel(f1_1, f1_2)\n",
    "print(\"feito.\")\n",
    "\n",
    "# Resultado e interpretação\n",
    "print(f\"p-value = {p_value:.4f}\")\n",
    "\n",
    "# Se p-value < 0.05 -> há evidência suficiente para rejeitar a hipótese nula.\n",
    "if p_value < 0.05:\n",
    "    print(\"Conclusão: diferença estatisticamente significativa.\")\n",
    "    melhor = modelo_1 if np.mean(f1_1) > np.mean(f1_2) else modelo_2\n",
    "    print(f\"Modelo com melhor desempenho: {melhor}\")\n",
    "else:\n",
    "    print(\"Conclusão: não há diferença estatisticamente significativa entre os dois modelos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "312ebbf6-95c9-4504-a46a-775c210b9081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (mean±std):\n",
      "  Melhor desempenho -> Árvore de Decisão (0.7562)\n",
      "  Pior desempenho   -> Rede Neuronal (0.5321)\n",
      "\n",
      "Sensitivity (mean±std):\n",
      "  Melhor desempenho -> Rede Neuronal (0.6279)\n",
      "  Pior desempenho   -> SVM (0.0006)\n",
      "\n",
      "Specificity (mean±std):\n",
      "  Melhor desempenho -> SVM (1.0000)\n",
      "  Pior desempenho   -> Rede Neuronal (0.4791)\n",
      "\n",
      "F1 (mean±std):\n",
      "  Melhor desempenho -> K-vizinhos (0.5206)\n",
      "  Pior desempenho   -> SVM (0.0011)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4.3\n",
    "# ALÍNEA 5 — Compare os resultados dos modelos.\n",
    "# Discuta qual apresentou melhor e pior desempenho em:\n",
    "# Accuracy, Sensitivity, Specificity e F1.\n",
    "# ============================================================\n",
    "\n",
    "# Extrair média de cada métrica para comparação\n",
    "metricas = df_results.copy()\n",
    "for coluna in metricas.columns:\n",
    "    metricas[coluna] = metricas[coluna].apply(lambda x: x[0])  # só a média, ignora std\n",
    "\n",
    "# Identificar o melhor e pior modelo por métrica\n",
    "for metrica in metricas.columns:\n",
    "    melhor_modelo = metricas[metrica].idxmax()\n",
    "    pior_modelo = metricas[metrica].idxmin()\n",
    "    valor_melhor = metricas[metrica].max()\n",
    "    valor_pior = metricas[metrica].min()\n",
    "\n",
    "    print(f\"{metrica}:\")\n",
    "    print(f\"  Melhor desempenho -> {melhor_modelo} ({valor_melhor:.4f})\")\n",
    "    print(f\"  Pior desempenho   -> {pior_modelo} ({valor_pior:.4f})\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf789ed-8754-4c93-b83c-f77189fd3f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ANADI)",
   "language": "python",
   "name": "anadi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
